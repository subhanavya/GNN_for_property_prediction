
host:
  workdir: .
  device: 1


model:
  hidden_dim: 200
  num_layers: 4
  dropout: 0.2
  graph_dim: 128
  batch_size: 64
  max_epochs: 200      # <-- number of epochs
  learning_rate: 0.0005
  weight_decay: 0.00001
  patience: 30

training:
  batch_size: 64
  max_epochs: 200
  learning_rate: 0.0005
  weight_decay: 1e-5
  patience: 30